{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0f0993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "GROUP_ID = 'Group27'\n",
    "ALGORITHM = 'ValItr' # ValItr, QLrng, or SARSA\n",
    "TRACK_NAME = 'provided/W-track.txt' # 2-track, U-track, or W-track\n",
    "CRASH_POS = 'NRST' # NRST or STRT. Determines whether car must re-start on crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35b4947b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17,37\n",
      "#####################################\n",
      "###########.....#####################\n",
      "##########.....######################\n",
      "#########.....#######################\n",
      "########.....########################\n",
      "#######.....#########################\n",
      "#S.................................F#\n",
      "#S.................................F#\n",
      "#S.................................F#\n",
      "#S.................................F#\n",
      "#S.................................F#\n",
      "############.....####################\n",
      "#############.....###################\n",
      "##############.....##################\n",
      "###############.....#################\n",
      "################.....################\n",
      "#####################################\n",
      "\n",
      "run Value Iteration\n",
      "k: 2\n",
      "k: 3\n",
      "k: 4\n",
      "k: 5\n",
      "k: 6\n",
      "k: 7\n",
      "k: 8\n",
      "k: 9\n",
      "k: 10\n",
      "k: 11\n",
      "k: 12\n",
      "k: 13\n",
      "k: 14\n",
      "k: 15\n",
      "k: 16\n",
      "k: 17\n",
      "k: 18\n",
      "k: 19\n",
      "k: 20\n",
      "k: 21\n",
      "Moves of Best Run: 9\n",
      "Best Path Taken: \n",
      "#####################################\n",
      "###########.....#####################\n",
      "##########.....######################\n",
      "#########.....#######################\n",
      "########.....########################\n",
      "#######.....#########################\n",
      "#PP.P..P...P....P....P....P...P....P#\n",
      "#S.................................F#\n",
      "#S.................................F#\n",
      "#S.................................F#\n",
      "#S.................................F#\n",
      "############.....####################\n",
      "#############.....###################\n",
      "##############.....##################\n",
      "###############.....#################\n",
      "################.....################\n",
      "#####################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random \n",
    "import sys\n",
    "import re\n",
    "import copy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Track:\n",
    "    # ---------------- INSTANTIATION ------------------\n",
    "    def __init__(self, track, crashReset, inputTextArray):\n",
    "        self.track = track # numpy array representing raw track grid\n",
    "        self.trackShape = track.shape\n",
    "        # 1 is 'S' aka Start, 2 is 'F' aka Finish, 0 is '.' aka track, 3 is '#', or wall. \n",
    "        self.crashReset = crashReset # Boolean, True or False. True if crash means restart, false if crash means start from previous position\n",
    "        # (with no velocity)\n",
    "        self.velocity = np.zeros(2, dtype = int) # representing velocity in x and y directions, respectively. \n",
    "        # positive x is left-to-right, positive y is up-to-down (think reading directions).\n",
    "        # both values must be between -5 and 5 (inclusive)\n",
    "        self.position = np.zeros(2, dtype = int) # initialized as (0, 0), \n",
    "        # but must be in approprate starting position (any 1 in self.track) upon start\n",
    "        # additionally, it must be within the bounds of walls. \n",
    "        self.acceleration = np.zeros(2, dtype = int) # both values must be between -1 and 1 (inclusive)\n",
    "        self.previousAcceleration = np.zeros(2, dtype = int) # Stores actual previous acceleration. may be used to track failed attempts\n",
    "        # (0.2 probability), or movement from previous position\n",
    "        self.previousAccelerationAttempt = np.zeros(2, dtype = int) # Stores agent's attempted previous acceleration attempt. \n",
    "        # may be used to track failed attempts (0.2 probability)\n",
    "        self.path = [] # array storing type 'np.zeros(2, dtype = int)'. Tracks every position of car way to finish line.\n",
    "        self.moves = 0 # tracks number of moves our AI has made. \n",
    "\n",
    "        self.inputTextArray = inputTextArray # numpy of actual input text. On output, will be used to display best path taken by learning method. \n",
    "        # on output, we replace the cells that are part of the path taken with 'P'. So, some '.' will become 'P'.\n",
    "        self.bestMoves = 9999 # tracks the number of moves associated with the best path taken. Will be printed to console on end of function.\n",
    "        self.bestPath = [] # stores the best path found by the algorithm\n",
    "\n",
    "        self.numberOfCrashes = 0 # tracks the number of crashes for debugging purposes\n",
    "\n",
    "        self.trackSize = 0 # number of non-wall elements\n",
    "        self.trackIDs = {} # stores a list of non-wall element locations [row, column], as ordered by sequential access of (row, column) index.\n",
    "        self.trackLocs = {} # stores all sequential access non-wall indexes, keys being a string representing the [row, column]\n",
    "        self.startingCells = [] # contains array of all starting cells. \n",
    "        # For value iteration, the best of self.valIterStates[startingCell][0][0][startingAccx][startingAccy] will be selected as our first position/move.\n",
    "        # Then, we will greedily follow that gradient to the finish to obtain our optimal path.\n",
    "        '''\n",
    "        for row in range(self.trackShape[0]):\n",
    "            for col in range(self.trackShape[1]):\n",
    "                item = self.track[row][col]\n",
    "                if (item == 1):\n",
    "                    self.startingCells.append([row, col])\n",
    "                    \n",
    "                if ((item == 0) or (item == 1) or (item == 2)):\n",
    "                    self.trackIDs.update({self.trackSize : [row, col]})\n",
    "                    self.trackLocs.update({str([row, col]) : self.trackSize})\n",
    "                    self.trackSize += 1''' \n",
    "\n",
    "        for row in range(self.trackShape[0]):\n",
    "            for col in range(self.trackShape[1]):\n",
    "                item = self.track[row][col]\n",
    "                if item == 1:\n",
    "                    self.startingCells.append((row, col))  \n",
    "                if item in (0, 1, 2):\n",
    "                    self.trackIDs[self.trackSize] = (row, col)   \n",
    "                    self.trackLocs[(row, col)] = self.trackSize  \n",
    "                    self.trackSize += 1\n",
    "                    \n",
    "        # array to contain the score for every possible state. The state is represented as:\n",
    "        # trackID, x velocity, y velocity, x acceleration, y acceleration\n",
    "        self.valIterStates = np.zeros((self.trackSize, 11, 11, 3, 3), dtype = float)\n",
    "        self.resultingStates = np.zeros((self.trackSize, 11, 11, 3, 3, 3), dtype = int) # lookup table for resulting states from valIterStates\n",
    "        \n",
    "    # ---------------- END INSTANTIATION ------------------\n",
    "\n",
    "\n",
    "    # ---------------- GET METHODS ------------------\n",
    "    '''\n",
    "    def getX(self):\n",
    "        # sample get expression\n",
    "        return self.X'''\n",
    "    def getFinishInfo(self):\n",
    "        fCells = []\n",
    "        for r in range(self.trackShape[0]):\n",
    "            for c in range(self.trackShape[1]):\n",
    "                if self.track[r][c] == 2:\n",
    "                    fCells.append((r, c))\n",
    "\n",
    "        # no finish line on track\n",
    "        if not fCells:\n",
    "            return None, []\n",
    "\n",
    "        # all fCells are on the same row in the tracks\n",
    "        finish_row = fCells[0][0]\n",
    "\n",
    "        # find close no wall states to use as goal while coding helps for exploration\n",
    "        goal_zone_ids = []\n",
    "        for tid, (r, c) in self.trackIDs.items():\n",
    "            # includes states from last rows above finish (3 now can change)\n",
    "            if r >= finish_row - 3:\n",
    "                goal_zone_ids.append(tid)\n",
    "\n",
    "        return finish_row, goal_zone_ids\n",
    "\n",
    "\n",
    "    def getInputTextArray(self):\n",
    "        # for output purposes\n",
    "        return self.inputTextArray\n",
    "\n",
    "    def getBestPath(self):\n",
    "        # for output purposes\n",
    "        return self.bestPath\n",
    "    \n",
    "    def getBestMoves(self):\n",
    "        # for output purposes\n",
    "        return self.bestMoves\n",
    "        \n",
    "    '''    \n",
    "    def getIsStart(self, posiiton):\n",
    "        isStart = False\n",
    "        # takes in a position and checks if that location on the graph is a '1'. If it is a '1', return true. Otherwise, return false\n",
    "        return isStart'''\n",
    "    '''    \n",
    "    def getIsFinish(self, posiiton):\n",
    "        isFinish = False\n",
    "        # takes in a position and checks if that location on the graph is a '2'. If it is a '2', return true. Otherwise, return false\n",
    "        return isFinish'''\n",
    "    '''\n",
    "    def getIsWall(self, posiiton):\n",
    "        isWall = False\n",
    "        # takes in a position and checks if that location on the graph is a '3'. If it is a '3', return true. Otherwise, return false\n",
    "        return isWall'''\n",
    "    # ---------------- END GET METHODS ------------------\n",
    "\n",
    "    # ---------------- ACTION METHODS  ------------------\n",
    "    '''\n",
    "    def getIsTrack(self, posiiton):\n",
    "        isWall = False\n",
    "        # takes in a position and checks if that location on the graph is a '0'. If it is a '0', return true. Otherwise, return false\n",
    "        return isWall'''\n",
    "    '''\n",
    "    def updateAcceleration(self, newAcceleration):\n",
    "        outOfBounds = False\n",
    "        # unconditionally updates self.acceleration, with values within bounds -1 and 1. Takes in a 2-size np.zeros array.\n",
    "        # always update self.previousAccelerationAttempt to this value. \n",
    "        # always update self.acceleration to this value. \n",
    "\n",
    "        # always append 1 to self.moves\n",
    "        \n",
    "        # return outOfBounds = True if the attempted set was out of allowed bounds\n",
    "        return outOfBounds\n",
    "        '''\n",
    "    '''\n",
    "    def failAcceleration(self):\n",
    "        failed = False\n",
    "        # run sequentially after self.updateAcceleration() (we can comment it's function calls out for consistency while\n",
    "        # debugging algorithms, then un-comment as one of the final steps)\n",
    "        # with probability 0.2, set failed to be True\n",
    "        # if failed is True, update self.acceleration to (0, 0)\n",
    "        # afterward, always update self.previousAcceleration to self.acceleration\n",
    "        return failed\n",
    "        '''\n",
    "    def updateVelocity(self):\n",
    "        outOfBounds = False\n",
    "        self.velocity[0] += self.acceleration[0]\n",
    "        self.velocity[1] += self.acceleration[1]\n",
    "        if (self.velocity[0] > 5):\n",
    "            self.velocity[0] = 5\n",
    "            outOfBounds = True\n",
    "        if (self.velocity[1] > 5):\n",
    "            self.velocity[1] = 5\n",
    "            outOfBounds = True\n",
    "        if (self.velocity[0] < -5):\n",
    "            self.velocity[0] = -5\n",
    "            outOfBounds = True\n",
    "        if (self.velocity[1] < -5):\n",
    "            self.velocity[1] = -5\n",
    "            outOfBounds = True\n",
    "        # run sequentially after self.failAcceleration()\n",
    "        # unconditionally updates self.velocity based upon self.acceleration\n",
    "        # add values in self.acceleration to self.velocity, ensuring self.velocity is within bounds\n",
    "        # return outOfBounds = True if the attempted set was out of allowed bounds\n",
    "        return outOfBounds\n",
    "        \n",
    "    def updatePosition(self):\n",
    "        collisionOccurred = False\n",
    "        # run sequentially after self.updateVelocity()\n",
    "        # unconditionally updates self.position based upon self.velocity\n",
    "        \n",
    "        # add values in self.acceleration to self.position, iteratively checking for collisions (i.e., if velocity is (-4, 2), \n",
    "        # check each position (x - 1, y + 0), (x - 2, y + 1), (x - 3, y + 1), (x - 4, y + 2).. or something...). \n",
    "        # for every position tested that is not a collision, append it to the self.path array\n",
    "        # if collision is detected, unconditionally update position to the previous tested position and move to next steps\n",
    "        # (keeps moving until it's up against wall it collides with)\n",
    "        # if finish line is encountered, stop it there. \n",
    "        xCounter = 0\n",
    "        yCounter = 0\n",
    "        for i in range(5):\n",
    "            xCounter += self.velocity[0]\n",
    "            yCounter += self.velocity[1]\n",
    "            xPosition = int(xCounter / 5) + self.position[0]\n",
    "            yPosition = int(yCounter / 5) + self.position[1]\n",
    "            locType = self.track[xPosition][yPosition]\n",
    "            if locType == 2:\n",
    "                self.position[0] = xPosition\n",
    "                self.position[1] = yPosition\n",
    "                return collisionOccurred\n",
    "            if locType == 3:\n",
    "                collisionOccurred = True\n",
    "                if not self.crashReset:\n",
    "                    self.position[0] = int((xCounter - self.velocity[0]) / 5) + self.position[0]\n",
    "                    self.position[1] = int((yCounter - self.velocity[1]) / 5) + self.position[1]\n",
    "                    self.velocity[0] = 0\n",
    "                    self.velocity[1] = 0\n",
    "                    return collisionOccurred\n",
    "                else:\n",
    "                    self.position[0] = self.startingCells[0][0]\n",
    "                    self.position[1] = self.startingCells[0][1]\n",
    "                    self.velocity[0] = 0\n",
    "                    self.velocity[1] = 0\n",
    "                    return collisionOccurred\n",
    "        \n",
    "        # if no collision occurs, set new position accordingly. \n",
    "        self.position[0] += self.velocity[0]\n",
    "        self.position[1] += self.velocity[1]\n",
    "        # if collision occurs, set self.velocity = 0, add 1 to self.numberOfCrashes\n",
    "        # if collision occurs, check self.crashReset Variable. If true, set position to start of track\n",
    "        \n",
    "        # return collisionOccurred = True if collision occurred\n",
    "        return collisionOccurred\n",
    "    # ---------------- END ACTION METHODS  ------------------\n",
    "\n",
    "    # ************************** SHARED METHODS *******************************\n",
    "    # ------------------------ DO MOVE ---------------------------------\n",
    "    def makeMove(self, move):\n",
    "        self.position[0] = move[0]\n",
    "        self.position[1] = move[1]\n",
    "        self.velocity[0] = move[2]\n",
    "        self.velocity[1] = move[3]\n",
    "        self.acceleration[0] = move[4]\n",
    "        self.acceleration[1] = move[5]\n",
    "        self.updateVelocity()\n",
    "        self.updatePosition()\n",
    "        trackID = self.trackLocs[(int(self.position[0]), int(self.position[1]))]\n",
    "        resultingState = [trackID, self.velocity[0], self.velocity[1], self.acceleration[0], self.acceleration[1]]\n",
    "        return resultingState\n",
    "\n",
    "    def attemptFinish(self, move): # checks if move touches or crosses finish line\n",
    "        self.position[0] = move[0]\n",
    "        self.position[1] = move[1]\n",
    "        self.velocity[0] = move[2]\n",
    "        self.velocity[1] = move[3]\n",
    "        self.acceleration[0] = move[4]\n",
    "        self.acceleration[1] = move[5]\n",
    "        self.updateVelocity()\n",
    "        self.updatePosition()\n",
    "        Finishes = False\n",
    "        oldTrackID = self.trackLocs[(move[0], move[1])]\n",
    "        trackID = self.trackLocs[(int(self.position[0]), int(self.position[1]))]\n",
    "        self.resultingStates[oldTrackID][move[2] + 5][move[3] + 5][move[4] + 1][move[5] + 1] = np.array([trackID, self.velocity[0] + 5, self.velocity[1] + 5])\n",
    "        if (self.track[self.position[0]][self.position[1]] == 2):\n",
    "            Finishes = True\n",
    "        return Finishes # returns false if move does not complete the race.\n",
    "    # ------------------------ END DO MOVE ---------------------------------\n",
    "\n",
    "    # ************************** END SHARED METHODS *******************************\n",
    "\n",
    "\n",
    "    # ************************** VALUE ITERATION METHODS *******************************\n",
    "    # ------------------------ DO VALUE ITERATION ---------------------------------\n",
    "    def doValueIteration(self):\n",
    "        self.doIterationK0()\n",
    "        self.doIterationK1()\n",
    "        valueUpdated = True\n",
    "        k = 2\n",
    "        while valueUpdated and (k < 100):\n",
    "            print(\"k: \" + str(k))\n",
    "            valueUpdated = self.doIterationKn(k)\n",
    "            k += 1\n",
    "\n",
    "        # next, find best starting conditions (use self.startingCells), then follow the gradient greedily to track path to finish line.\n",
    "        # update self.moves and self.bestPath along the way\n",
    "        # from the best starting cell, track best path deterministically to finish (we are just recording our findings, this is not \n",
    "        # an actual simulation)\n",
    "        \n",
    "        bestStart = [self.trackLocs[self.startingCells[0]], 0, 0]\n",
    "        bestStartValue = -99999\n",
    "        for cell in self.startingCells:\n",
    "            startingID = self.trackLocs[cell]\n",
    "            for xaccIndex in range(3):\n",
    "                for yaccIndex in range(3):\n",
    "                    startValue = self.valIterStates[startingID][5][5][xaccIndex][yaccIndex]\n",
    "                    if (startValue > bestStartValue):\n",
    "                        bestStart = [startingID, xaccIndex, yaccIndex]\n",
    "                        bestStartValue = startValue\n",
    "                        \n",
    "        startPosition = self.trackIDs[bestStart[0]]\n",
    "        self.position[0] = startPosition[0]\n",
    "        self.position[1] = startPosition[1]\n",
    "        self.bestPath.append([self.position[0], self.position[1]])\n",
    "        self.acceleration[0] = bestStart[1] - 1\n",
    "        self.acceleration[1] = bestStart[2] - 1\n",
    "        self.updateVelocity()\n",
    "        self.updatePosition()\n",
    "        self.bestMoves = 1\n",
    "        self.bestPath.append([self.position[0], self.position[1]])\n",
    "        \n",
    "        while self.track[self.position[0]][self.position[1]] != 2:\n",
    "            bestMoveValue = -99999\n",
    "            bestMove = [0, 0]\n",
    "            cellID = self.trackLocs[(int(self.position[0]), int(self.position[1]))]\n",
    "            for xaccIndex in range(3):\n",
    "                for yaccIndex in range(3):\n",
    "                    moveValue = self.valIterStates[cellID][self.velocity[0] + 5][self.velocity[1] + 5][xaccIndex][yaccIndex]\n",
    "                    if (moveValue > bestMoveValue):\n",
    "                        bestMove = [xaccIndex - 1, yaccIndex - 1]\n",
    "                        bestMoveValue = moveValue\n",
    "            self.acceleration[0] = bestMove[0]\n",
    "            self.acceleration[1] = bestMove[1]\n",
    "            self.updateVelocity()\n",
    "            self.updatePosition()\n",
    "            self.bestMoves += 1\n",
    "            self.bestPath.append([self.position[0], self.position[1]])\n",
    "        \n",
    "        return\n",
    "\n",
    "    def doIterationK0(self):\n",
    "        locIndex = 0\n",
    "        for loc in self.valIterStates:\n",
    "            xy = self.trackIDs[locIndex]\n",
    "            xpos = xy[0]\n",
    "            ypos = xy[1]\n",
    "            if (self.track[xpos][ypos] != 2):   \n",
    "                xVelIndex = 0\n",
    "                for xvel in loc:\n",
    "                    yVelIndex = 0\n",
    "                    for yvel in xvel:\n",
    "                        xAccIndex = 0\n",
    "                        for xacc in yvel:\n",
    "                            yAccIndex = 0\n",
    "                            for yacc in xacc:\n",
    "                                self.valIterStates[locIndex, xVelIndex, yVelIndex, xAccIndex, yAccIndex] = -1.0\n",
    "                                yAccIndex += 1\n",
    "                            xAccIndex += 1\n",
    "                        yVelIndex += 1\n",
    "                    xVelIndex += 1\n",
    "            locIndex += 1\n",
    "        return\n",
    "\n",
    "    def doIterationK1(self):\n",
    "        locIndex = 0\n",
    "        for loc in self.valIterStates:\n",
    "            xy = self.trackIDs[locIndex]\n",
    "            xpos = xy[0]\n",
    "            ypos = xy[1]\n",
    "            xvelVal = -5\n",
    "            for xvel in loc:\n",
    "                xVelIndex = xvelVal + 5\n",
    "                \n",
    "                yvelVal = -5\n",
    "                for yvel in xvel:\n",
    "                    yVelIndex = yvelVal + 5\n",
    "                    \n",
    "                    xaccVal = -1\n",
    "                    for xacc in yvel:\n",
    "                        xAccIndex = xaccVal + 1\n",
    "                        \n",
    "                        yaccVal = -1\n",
    "                        for yacc in xacc:\n",
    "                            yAccIndex = yaccVal + 1\n",
    "                            move = [xpos, ypos, xvelVal, yvelVal, xaccVal, yaccVal]\n",
    "                            finishes = self.attemptFinish(move)\n",
    "                            if not finishes:\n",
    "                                self.valIterStates[locIndex, xVelIndex, yVelIndex, xAccIndex, yAccIndex] += -0.999 * 0.8\n",
    "                            yaccVal += 1\n",
    "                        xaccVal += 1\n",
    "                    yvelVal += 1\n",
    "                xvelVal += 1\n",
    "            locIndex += 1\n",
    "        # for 20% chance of failure\n",
    "        locIndex = 0\n",
    "        for loc in self.valIterStates:\n",
    "            xy = self.trackIDs[locIndex]\n",
    "            xpos = xy[0]\n",
    "            ypos = xy[1]\n",
    "            xvelVal = -5\n",
    "            for xvel in loc:\n",
    "                xVelIndex = xvelVal + 5\n",
    "                \n",
    "                yvelVal = -5\n",
    "                for yvel in xvel:\n",
    "                    yVelIndex = yvelVal + 5\n",
    "                    \n",
    "                    move = [xpos, ypos, xvelVal, yvelVal, 1, 1]\n",
    "                    finishes = self.attemptFinish(move)\n",
    "                    \n",
    "                    xaccVal = -1\n",
    "                    for xacc in yvel:\n",
    "                        xAccIndex = xaccVal + 1\n",
    "                        \n",
    "                        yaccVal = -1\n",
    "                        for yacc in xacc:\n",
    "                            yAccIndex = yaccVal + 1\n",
    "                            if not finishes: \n",
    "                                self.valIterStates[locIndex, xVelIndex, yVelIndex, xAccIndex, yAccIndex] += -0.999 * 0.2\n",
    "                            yaccVal += 1\n",
    "                        xaccVal += 1\n",
    "                    yvelVal += 1\n",
    "                xvelVal += 1\n",
    "            locIndex += 1 \n",
    "        return\n",
    "        \n",
    "    def doIterationKn(self, k):\n",
    "        valueRemoved = -(0.999**k)\n",
    "        kMinus2Value = 0\n",
    "        for i in range(k - 1): # iterations start from 0, not 1. So i is already k - 1. So i - 1 is k - 2. Really is confusing, though...\n",
    "            kMinus2Value += -(1 * (0.999**i))\n",
    "\n",
    "        valueUpdated = False\n",
    "        pathFound1 = False # will need to be corrected for non-deterministic\n",
    "        pathFound2 = False # will need to be corrected for non-deterministic\n",
    "        locIndex = 0\n",
    "        for loc in self.valIterStates:\n",
    "            #print(\"locIndex: \" + str(locIndex))\n",
    "            xy = self.trackIDs[locIndex]\n",
    "            xpos = xy[0]\n",
    "            ypos = xy[1]\n",
    "            xvelVal = -5\n",
    "            for xvel in loc:\n",
    "                xVelIndex = xvelVal + 5\n",
    "                \n",
    "                yvelVal = -5\n",
    "                for yvel in xvel:\n",
    "                    yVelIndex = yvelVal + 5\n",
    "                    \n",
    "                    xaccVal = -1\n",
    "                    for xacc in yvel:\n",
    "                        xAccIndex = xaccVal + 1\n",
    "                        \n",
    "                        yaccVal = -1\n",
    "                        for yacc in xacc:\n",
    "                            yAccIndex = yaccVal + 1\n",
    "                            # move = [xpos, ypos, xvelVal, yvelVal, xaccVal, yaccVal]\n",
    "                            nextState = self.resultingStates[locIndex][xVelIndex][yVelIndex][xAccIndex][yAccIndex]\n",
    "                            nextValue = np.max(self.valIterStates[nextState[0]][nextState[1]][nextState[2]][:][:])\n",
    "                            improves = (nextValue >= kMinus2Value) # the .8 breaks this comparison, skip for now.\n",
    "                            if not improves: \n",
    "                                self.valIterStates[locIndex, xVelIndex, yVelIndex, xAccIndex, yAccIndex] += valueRemoved * 0.8\n",
    "                                valueUpdated = True\n",
    "                            if (self.track[xpos][ypos] == 1) and improves and (xvelVal == 0) and (yvelVal == 0):\n",
    "                                pathFound1 = True # will need to be corrected for non-deterministic\n",
    "                            yaccVal += 1\n",
    "                        xaccVal += 1\n",
    "                    yvelVal += 1\n",
    "                xvelVal += 1\n",
    "            locIndex += 1\n",
    "        # for 20% chance of failure\n",
    "        locIndex = 0\n",
    "        for loc in self.valIterStates:\n",
    "            #print(\"locIndex: \" + str(locIndex))\n",
    "            xy = self.trackIDs[locIndex]\n",
    "            xpos = xy[0]\n",
    "            ypos = xy[1]\n",
    "            xvelVal = -5\n",
    "            for xvel in loc:\n",
    "                xVelIndex = xvelVal + 5\n",
    "                \n",
    "                yvelVal = -5\n",
    "                for yvel in xvel:\n",
    "                    yVelIndex = yvelVal + 5\n",
    "\n",
    "                    # move = [xpos, ypos, xvelVal, yvelVal, 1, 1]\n",
    "                    nextState = self.resultingStates[locIndex][xVelIndex][yVelIndex][1][1]\n",
    "                    nextValue = np.max(self.valIterStates[nextState[0]][nextState[1]][nextState[2]][:][:])\n",
    "                    improves = (nextValue >= kMinus2Value) # the .8 breaks this comparison, skip for now.\n",
    "                    if not improves: \n",
    "                        xaccVal = -1\n",
    "                        for xacc in yvel:\n",
    "                            xAccIndex = xaccVal + 1\n",
    "\n",
    "                            yaccVal = -1\n",
    "                            for yacc in xacc:\n",
    "                                yAccIndex = yaccVal + 1\n",
    "                                self.valIterStates[locIndex, xVelIndex, yVelIndex, xAccIndex, yAccIndex] += valueRemoved * 0.2\n",
    "                                valueUpdated = True\n",
    "                                yaccVal += 1\n",
    "                            if (self.track[xpos][ypos] == 1) and improves and (xvelVal == 0) and (yvelVal == 0):\n",
    "                                pathFound2 = True # will need to be corrected for non-deterministic\n",
    "                            xaccVal += 1\n",
    "                    yvelVal += 1\n",
    "                xvelVal += 1\n",
    "            locIndex += 1 \n",
    "        if pathFound1 and pathFound2:\n",
    "            valueUpdated = False\n",
    "        return valueUpdated\n",
    "        \n",
    "    # ------------------------ END DO VALUE ITERATION ---------------------------------\n",
    "\n",
    "    # ************************** END VALUE ITERATION METHODS *******************************\n",
    "\n",
    "\n",
    "    # ************************** Q-LEARNING METHODS *******************************\n",
    "    # ------------------------ DO Q-LEARNING ---------------------------------\n",
    "    def doQLearning(self):\n",
    "        # q table with one value for every state or action...\n",
    "        # state is just track ID, vs, vy. action is just ax, ay\n",
    "        qVals = np.zeros((self.trackSize, 11, 11, 3, 3), dtype=float)\n",
    "\n",
    "        # different accelerations (only -1, 0 1 for forward stopped reverse)\n",
    "        accelerations = []\n",
    "        for ax in [-1, 0, 1]:\n",
    "            for ay in [-1, 0, 1]:\n",
    "                accelerations.append((ax, ay))\n",
    "\n",
    "        # learning params\n",
    "        learningRate = 0.1      # learning rate\n",
    "        discount = 0.95     # discounting current vs future reward\n",
    "        randomStart = 0.3    # exploration rate from beginning\n",
    "        randomMin = 0.01    # random freq\n",
    "        randomDecay = 0.995  # after every ep multiply randomStart by .995\n",
    "\n",
    "        episodeNumber = 20000      # more training (past this laptop starts to suck)\n",
    "        maxSteps = 10000\n",
    "\n",
    "        # get index for the current state\n",
    "        def getStateIndex():\n",
    "            trackID = self.trackLocs[(int(self.position[0]), int(self.position[1]))]\n",
    "            vxIDX = self.velocity[0] + 5\n",
    "            vyIDX = self.velocity[1] + 5\n",
    "            return trackID, vxIDX, vyIDX\n",
    "\n",
    "        # get index for action\n",
    "        def getActionIndex(action):\n",
    "            ax, ay = action\n",
    "            return ax + 1, ay + 1\n",
    "\n",
    "        # choose action explore or exploit\n",
    "        def chooseAction(trackID, vxIDX, vyIDX, eps):\n",
    "            if random.random() < eps:\n",
    "                # random action\n",
    "                return random.choice(accelerations)\n",
    "            # greedy action\n",
    "            qSlice = qVals[trackID, vxIDX, vyIDX]\n",
    "            qMax = np.max(qSlice)\n",
    "            bestIndex = np.argwhere(qSlice == qMax)\n",
    "            idx = random.choice(bestIndex)\n",
    "            axIDX = int(idx[0])\n",
    "            ayIDX = int(idx[1])\n",
    "            return axIDX - 1, ayIDX - 1\n",
    "\n",
    "        # apply an action once during training\n",
    "        # crashes and finishes at end of episode\n",
    "        def applyActionTrain(action):\n",
    "            ax, ay = action\n",
    "\n",
    "            # attempted accelerate\n",
    "            self.acceleration[0] = ax\n",
    "            self.acceleration[1] = ay\n",
    "\n",
    "            # 20 percent chance the acceleration fails (as required)\n",
    "            if random.random() < 0.2:\n",
    "                self.acceleration[0] = 0\n",
    "                self.acceleration[1] = 0\n",
    "\n",
    "            # TO DISABLE CRASH RESET\n",
    "            # crashReset = self.crashReset\n",
    "            # self.crashReset = False\n",
    "\n",
    "            # update velo and pos\n",
    "            self.updateVelocity()\n",
    "            crash = self.updatePosition()  # True when hit wall\n",
    "\n",
    "            # put back original crash reset rules\n",
    "            # self.crashReset = crashReset\n",
    "\n",
    "            # if you reach finish then reward (1000 seemed good for me generally\n",
    "            if self.track[self.position[0]][self.position[1]] == 2:\n",
    "                return 1000.0, True\n",
    "\n",
    "\n",
    "            # crash, consequence of q worked while then continue=false\n",
    "            # if crash and self.crashReset:\n",
    "                #=return -10.0, False\n",
    "\n",
    "            # a normal move is a small negative cost\n",
    "            return -1.0, False\n",
    "\n",
    "\n",
    "\n",
    "        # apply an action once during eval\n",
    "        # crashes follow the actual guidelines nearest or restart\n",
    "        def applyActionEval(action):\n",
    "            ax, ay = action\n",
    "\n",
    "            self.acceleration[0] = ax\n",
    "            self.acceleration[1] = ay\n",
    "\n",
    "            # REMOVED for coding XX\n",
    "            # if random.random() < 0.2:\n",
    "            #     self.acceleration[0] = 0\n",
    "            #     self.acceleration[1] = 0\n",
    "    \n",
    "            self.updateVelocity()\n",
    "            self.updatePosition()\n",
    "\n",
    "            if self.track[self.position[0]][self.position[1]] == 2:\n",
    "                return 0.0, True\n",
    "            else:\n",
    "                return -1.0, False\n",
    "\n",
    "\n",
    "        # reset best path stats\n",
    "        self.bestPath = []\n",
    "        self.bestMoves = 9999\n",
    "\n",
    "        # q learning loop\n",
    "        finish_row, goal_zone_ids = self.getFinishInfo()\n",
    "\n",
    "        for ep in range(episodeNumber):\n",
    "\n",
    "            #   goal based exploring starts\n",
    "            if goal_zone_ids and ep < int(0.5 * episodeNumber):\n",
    "                # first .5 of training start near goal\n",
    "                if random.random() < 0.7:\n",
    "                    # .7 of the time start in goal zone\n",
    "                    randID = random.choice(goal_zone_ids)\n",
    "                else:\n",
    "                    randID = random.randrange(self.trackSize)\n",
    "            else:\n",
    "                # after uniform over over no wall states\n",
    "                randID = random.randrange(self.trackSize)\n",
    "\n",
    "            start = self.trackIDs[randID]\n",
    "\n",
    "            self.position[0] = start[0]\n",
    "            self.position[1] = start[1]\n",
    "            self.velocity[0] = 0\n",
    "            self.velocity[1] = 0\n",
    "            self.acceleration[0] = 0\n",
    "            self.acceleration[1] = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            for _step in range(maxSteps):\n",
    "                trackID, vxIDX, vyIDX = getStateIndex()\n",
    "                action = chooseAction(trackID, vxIDX, vyIDX, randomStart)\n",
    "                axIDX, ayIDX = getActionIndex(action)\n",
    "\n",
    "                # current q val\n",
    "                qOld = qVals[trackID, vxIDX, vyIDX, axIDX, ayIDX]\n",
    "\n",
    "                # action, see reward, next state\n",
    "                reward, done = applyActionTrain(action)\n",
    "                nextTID, nextVXIDX, nextVYIDX = getStateIndex()\n",
    "\n",
    "                if done:\n",
    "                    # no more reward\n",
    "                    qTarg = reward\n",
    "                else:\n",
    "                    # update based on the most valued next act\n",
    "                    next_q_max = np.max(\n",
    "                        qVals[nextTID, nextVXIDX, nextVYIDX]\n",
    "                    )\n",
    "                    qTarg = reward + discount * next_q_max\n",
    "\n",
    "                # q learn update\n",
    "                qVals[trackID, vxIDX, vyIDX, axIDX, ayIDX] = (\n",
    "                    qOld + learningRate * (qTarg - qOld)\n",
    "                )\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            # reduce exploration after each ep\n",
    "            if randomStart > randomMin:\n",
    "                randomStart *= randomDecay\n",
    "\n",
    "        # run w no exploration for bestPath and bestMoves\n",
    "        maxSteps = 500\n",
    "        bestLength = None\n",
    "        bestPath = []\n",
    "\n",
    "        for start in self.startingCells:\n",
    "            # put agent at current start\n",
    "            self.position[0] = start[0]\n",
    "            self.position[1] = start[1]\n",
    "            self.velocity[0] = 0\n",
    "            self.velocity[1] = 0\n",
    "            self.acceleration[0] = 0\n",
    "            self.acceleration[1] = 0\n",
    "\n",
    "            path = [[self.position[0], self.position[1]]]\n",
    "\n",
    "            for _step in range(maxSteps):\n",
    "                trackID, vxIDX, vyIDX = getStateIndex()\n",
    "                # no random choose just the best move\n",
    "                qSlice = qVals[trackID, vxIDX, vyIDX]\n",
    "                qMax = np.max(qSlice)\n",
    "                bestIndex = np.argwhere(qSlice == qMax)\n",
    "                idx = random.choice(bestIndex)\n",
    "                axIDX = int(idx[0])\n",
    "                ayIDX = int(idx[1])\n",
    "                action = (axIDX - 1, ayIDX - 1)\n",
    "\n",
    "                reward, done = applyActionEval(action)\n",
    "                path.append([self.position[0], self.position[1]])\n",
    "\n",
    "                if done:\n",
    "                    pathLength = len(path) - 1  # number moves\n",
    "                    if (bestLength is None) or (pathLength < bestLength):\n",
    "                        bestLength = pathLength\n",
    "                        bestPath = path[:]\n",
    "                    break\n",
    "\n",
    "        # if no finish reached in eval still keep last path\n",
    "        if bestLength is None:\n",
    "            #  use last start cell path\n",
    "            start = self.startingCells[0]\n",
    "            self.position[0] = start[0]\n",
    "            self.position[1] = start[1]\n",
    "            self.velocity[0] = 0\n",
    "            self.velocity[1] = 0\n",
    "            self.acceleration[0] = 0\n",
    "            self.acceleration[1] = 0\n",
    "\n",
    "            path = [[self.position[0], self.position[1]]]\n",
    "            for _step in range(maxSteps):\n",
    "                trackID, vxIDX, vyIDX = getStateIndex()\n",
    "                qSlice = qVals[trackID, vxIDX, vyIDX]\n",
    "                qMax = np.max(qSlice)\n",
    "                bestIndex = np.argwhere(qSlice == qMax)\n",
    "                idx = random.choice(bestIndex)\n",
    "                axIDX = int(idx[0])\n",
    "                ayIDX = int(idx[1])\n",
    "                action = (axIDX - 1, ayIDX - 1)\n",
    "\n",
    "                reward, done = applyActionEval(action)\n",
    "                path.append([self.position[0], self.position[1]])\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            self.bestPath = path\n",
    "            self.bestMoves = len(path) - 1\n",
    "        else:\n",
    "            self.bestPath = bestPath\n",
    "            self.bestMoves = bestLength\n",
    "\n",
    "        return\n",
    "    # ------------------------ END DO Q-LEARNING ---------------------------------\n",
    "\n",
    "    # ************************** END Q-LEARNING METHODS *******************************\n",
    "\n",
    "\n",
    "    # ************************** SARSA METHODS *******************************\n",
    "    # ------------------------ DO SARSA ---------------------------------\n",
    "    def doSARSA(self):\n",
    "        # q table with one value for every state or action...\n",
    "        qVals = np.zeros((self.trackSize, 11, 11, 3, 3), dtype=float)\n",
    "\n",
    "        # possible accelerations ( 1, 0, -1 start stopped go, project outlines)\n",
    "        actions = []\n",
    "        for ax in [-1, 0, 1]:\n",
    "            for ay in [-1, 0, 1]:\n",
    "                actions.append((ax, ay))\n",
    "\n",
    "        # learning params\n",
    "        learningRate = 0.1      # learning rate\n",
    "        discount = 0.95     # discounting current vs future reward\n",
    "        randomStart = 0.3     # exploration rate from beginning\n",
    "        randomMin = 0.01    # random freq\n",
    "        randomDecay = 0.995   # after every ep multiply randomStart by .995\n",
    "\n",
    "        episodeNumber = 20000      # more training (past this laptop starts to suck)\n",
    "        maxSteps = 10000\n",
    "\n",
    "        # get index for the current state\n",
    "        def getStateIndex():\n",
    "            trackID = self.trackLocs[(int(self.position[0]), int(self.position[1]))]\n",
    "            vxIDX = self.velocity[0] + 5\n",
    "            vyIDX = self.velocity[1] + 5\n",
    "            return trackID, vxIDX, vyIDX\n",
    "\n",
    "         # get index for action\n",
    "        def getActionIndex(action):\n",
    "            ax, ay = action\n",
    "            return ax + 1, ay + 1\n",
    "\n",
    "        # choose action explore or exploit\n",
    "        def chooseAction(trackID, vxIDX, vyIDX, eps):\n",
    "            if random.random() < eps:\n",
    "                return random.choice(actions)\n",
    "            qSlice = qVals[trackID, vxIDX, vyIDX]\n",
    "            qMax = np.max(qSlice)\n",
    "            bestIndex = np.argwhere(qSlice == qMax)\n",
    "            idx = random.choice(bestIndex)\n",
    "            axIDX = int(idx[0])\n",
    "            ayIDX = int(idx[1])\n",
    "            return axIDX - 1, ayIDX - 1\n",
    "\n",
    "        # execute a single training ep\n",
    "        # crashes or finish will end the episode\n",
    "        def applyActionTrain(action):\n",
    "            ax, ay = action\n",
    "\n",
    "            self.acceleration[0] = ax\n",
    "            self.acceleration[1] = ay\n",
    "\n",
    "            # .2 chance accel fails (proj specs)\n",
    "            if random.random() < 0.2:\n",
    "                self.acceleration[0] = 0\n",
    "                self.acceleration[1] = 0\n",
    "\n",
    "            # TOGGLE CRASH RESET FOR CODE XX\n",
    "            # crashReset = self.crashReset\n",
    "            # self.crashReset = False\n",
    "\n",
    "            self.updateVelocity()\n",
    "            crash = self.updatePosition()\n",
    "\n",
    "            # put back original crash reset rules\n",
    "            # self.crashReset = crashReset\n",
    "\n",
    "            # if you reach finish then reward (1000 seemed good for me generall) \n",
    "            if self.track[self.position[0]][self.position[1]] == 2:\n",
    "                return 1000.0, True\n",
    "\n",
    "\n",
    "            # crash, consequence of q worked while then continue=false\n",
    "            # if crash:\n",
    "                # return -10.0, False\n",
    "\n",
    "            # a normal move is a small negative step\n",
    "            return -1.0, False\n",
    "\n",
    "\n",
    "\n",
    "        # apply action once during eval\n",
    "        # crashes follow proj guidelines\n",
    "        def applyActionEval(action):\n",
    "            ax, ay = action\n",
    "\n",
    "            self.acceleration[0] = ax\n",
    "            self.acceleration[1] = ay\n",
    "\n",
    "            # .2 accel fails, assignment specs commented for coding XX\n",
    "           # if random.random() < 0.2:\n",
    "           #     self.acceleration[0] = 0\n",
    "           #     self.acceleration[1] = 0\n",
    "\n",
    "            self.updateVelocity()\n",
    "            self.updatePosition()\n",
    "\n",
    "            if self.track[self.position[0]][self.position[1]] == 2:\n",
    "                return 0.0, True\n",
    "            else:\n",
    "                return -1.0, False\n",
    "\n",
    "        # count reset for shortest path\n",
    "        self.bestPath = []\n",
    "        self.bestMoves = 9999\n",
    "\n",
    "        # sarsa training\n",
    "        finish_row, goal_zone_ids = self.getFinishInfo()\n",
    "\n",
    "        for ep in range(episodeNumber):\n",
    "\n",
    "            if goal_zone_ids and ep < int(0.5 * episodeNumber):\n",
    "                if random.random() < 0.7:\n",
    "                    randID = random.choice(goal_zone_ids)\n",
    "                else:\n",
    "                    randID = random.randrange(self.trackSize)\n",
    "            else:\n",
    "                randID = random.randrange(self.trackSize)\n",
    "\n",
    "            start = self.trackIDs[randID]\n",
    "\n",
    "            self.position[0] = start[0]\n",
    "            self.position[1] = start[1]\n",
    "            self.velocity[0] = 0\n",
    "            self.velocity[1] = 0\n",
    "            self.acceleration[0] = 0\n",
    "            self.acceleration[1] = 0\n",
    "\n",
    "            trackID, vxIDX, vyIDX = getStateIndex()\n",
    "            action = chooseAction(trackID, vxIDX, vyIDX, randomStart)\n",
    "\n",
    "            for _step in range(maxSteps):\n",
    "                axIDX, ayIDX = getActionIndex(action)\n",
    "                qOld = qVals[trackID, vxIDX, vyIDX, axIDX, ayIDX]\n",
    "\n",
    "                reward, done = applyActionTrain(action)\n",
    "                nextTID, nextVXIDX, nextVYIDX = getStateIndex()\n",
    "\n",
    "                if done:\n",
    "                    # ep ends here and updates bc no future value to add\n",
    "                    qTarg = reward\n",
    "                    qVals[trackID, vxIDX, vyIDX, axIDX, ayIDX] = (\n",
    "                        qOld + learningRate * (qTarg - qOld)\n",
    "                    )\n",
    "                    break\n",
    "                else:\n",
    "                    # pick next action w current exploration rate\n",
    "                    nextAct = chooseAction(nextTID, nextVXIDX, nextVYIDX, randomStart)\n",
    "                    nextAXIDX, nextAYIDX = getActionIndex(nextAct)\n",
    "                    qNext = qVals[nextTID, nextVXIDX, nextVYIDX, nextAXIDX, nextAYIDX]\n",
    "                    qTarg = reward + discount * qNext\n",
    "                    qVals[trackID, vxIDX, vyIDX, axIDX, ayIDX] = (\n",
    "                        qOld + learningRate * (qTarg - qOld)\n",
    "                    )\n",
    "\n",
    "                    # update state/action for next step\n",
    "                    trackID, vxIDX, vyIDX = nextTID, nextVXIDX, nextVYIDX\n",
    "                    action = nextAct\n",
    "\n",
    "            # reduce exploration after every ep\n",
    "            if randomStart > randomMin:\n",
    "                randomStart *= randomDecay\n",
    "\n",
    "        # test created policy with greedy sims\n",
    "        maxSteps = 500\n",
    "        bestLength = None\n",
    "        bestPath = []\n",
    "\n",
    "        for start in self.startingCells:\n",
    "            self.position[0] = start[0]\n",
    "            self.position[1] = start[1]\n",
    "            self.velocity[0] = 0\n",
    "            self.velocity[1] = 0\n",
    "            self.acceleration[0] = 0\n",
    "            self.acceleration[1] = 0\n",
    "\n",
    "            path = [[self.position[0], self.position[1]]]\n",
    "\n",
    "            for _step in range(maxSteps):\n",
    "                trackID, vxIDX, vyIDX = getStateIndex()\n",
    "                # choose action w greatest q val\n",
    "                qSlice = qVals[trackID, vxIDX, vyIDX]\n",
    "                qMax = np.max(qSlice)\n",
    "                bestIndex = np.argwhere(qSlice == qMax)\n",
    "                idx = random.choice(bestIndex)\n",
    "                axIDX = int(idx[0])\n",
    "                ayIDX = int(idx[1])\n",
    "                action = (axIDX - 1, ayIDX - 1)\n",
    "\n",
    "                reward, done = applyActionEval(action)\n",
    "                path.append([self.position[0], self.position[1]])\n",
    "\n",
    "                if done:\n",
    "                    pathLength = len(path) - 1\n",
    "                    if (bestLength is None) or (pathLength < bestLength):\n",
    "                        bestLength = pathLength\n",
    "                        bestPath = path[:]\n",
    "                    break\n",
    "\n",
    "        if bestLength is None:\n",
    "            # use fallback if if no policy reaches finish\n",
    "            start = self.startingCells[0]\n",
    "            self.position[0] = start[0]\n",
    "            self.position[1] = start[1]\n",
    "            self.velocity[0] = 0\n",
    "            self.velocity[1] = 0\n",
    "            self.acceleration[0] = 0\n",
    "            self.acceleration[1] = 0\n",
    "\n",
    "            path = [[self.position[0], self.position[1]]]\n",
    "            for _step in range(maxSteps):\n",
    "                trackID, vxIDX, vyIDX = getStateIndex()\n",
    "                qSlice = qVals[trackID, vxIDX, vyIDX]\n",
    "                qMax = np.max(qSlice)\n",
    "                bestIndex = np.argwhere(qSlice == qMax)\n",
    "                idx = random.choice(bestIndex)\n",
    "                axIDX = int(idx[0])\n",
    "                ayIDX = int(idx[1])\n",
    "                action = (axIDX - 1, ayIDX - 1)\n",
    "\n",
    "                reward, done = applyActionEval(action)\n",
    "                path.append([self.position[0], self.position[1]])\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            self.bestPath = path\n",
    "            self.bestMoves = len(path) - 1\n",
    "        else:\n",
    "            self.bestPath = bestPath\n",
    "            self.bestMoves = bestLength\n",
    "            \n",
    "        return\n",
    "\n",
    "\n",
    "    # ------------------------ END DO SARSA ---------------------------------\n",
    "\n",
    "    # ************************** END SARSA METHODS *******************************\n",
    "\n",
    "    \n",
    "def fileImport(fileName): # brings file into program as str numpy array\n",
    "    inputText = ''\n",
    "    with open(fileName, \"r\") as f:\n",
    "        inputText = f.read()\n",
    "    print(inputText)\n",
    "    textRows = inputText.split('\\n')\n",
    "    dimTxt = textRows[0].split(',')\n",
    "\n",
    "    numRows = int(dimTxt[0])\n",
    "    numCols = int(dimTxt[1])\n",
    "\n",
    "    inputTextArray = np.zeros((numRows, numCols), dtype = str)\n",
    "\n",
    "    for row in range(numRows):\n",
    "        # currentRow = textRows[row + 1].split()\n",
    "        for col in range(numCols):\n",
    "            inputTextArray[row][col] = textRows[row + 1][col]\n",
    "            \n",
    "    # print(inputTextArray)\n",
    "    \n",
    "    return inputTextArray\n",
    "\n",
    "def createTrack(inputTextArray, CRASH_POS):\n",
    "    rows = inputTextArray.shape[0]\n",
    "    cols = inputTextArray.shape[1]\n",
    "\n",
    "    trackIntegers = np.zeros((rows, cols), dtype = int)\n",
    "\n",
    "    # 1 is 'S' aka Start, 2 is 'F' aka Finish, 0 is '.' aka track, 3 is '#', or wall. \n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            character = inputTextArray[row][col]\n",
    "            if (character == 'S'):\n",
    "                trackIntegers[row][col] = 1\n",
    "            if (character == 'F'):\n",
    "                trackIntegers[row][col] = 2\n",
    "            if (character == '#'):\n",
    "                trackIntegers[row][col] = 3\n",
    "\n",
    "    crashReset = False\n",
    "\n",
    "    if (CRASH_POS == 'STRT'):\n",
    "        crashReset = True\n",
    "    elif (CRASH_POS != 'NRST'):\n",
    "        print(\"CRASH_POS invalid, defaulting to NRST setting (nearest non-crash position)\")\n",
    "        \n",
    "    track = Track(trackIntegers , crashReset, inputTextArray)\n",
    "    \n",
    "    return track\n",
    "\n",
    "import matplotlib.pyplot as plt   #  only this import is needed\n",
    "\n",
    "def saveOutput(GROUP_ID, ALGORITHM, TRACK_NAME, CRASH_POS, track):\n",
    "\n",
    "    trackPathArr = TRACK_NAME.split('/')\n",
    "    trackName = trackPathArr[-1]\n",
    "    # txtFileName = GROUP_ID + \"*\" + ALGORITHM + \"*\" + trackName[:-4] + \"*\" + CRASH_POS + \".txt\"\n",
    "    \n",
    "    writeArray = track.getInputTextArray().copy() \n",
    "    path = track.getBestPath()\n",
    "    writeString = ''\n",
    "    \n",
    "    for pos in path:\n",
    "        writeArray[pos[0]][pos[1]] = 'P'\n",
    "    \n",
    "    for row in writeArray:\n",
    "        for col in row:\n",
    "            writeString += col\n",
    "        writeString += '\\n'\n",
    "    \n",
    "    #with open(txtFileName, \"w\") as f:\n",
    "        #f.write(writeString)\n",
    "    \n",
    "    print(\"Best Path Taken: \")\n",
    "    print(writeString)\n",
    "\n",
    "    pngFileName = GROUP_ID + \"_\" + ALGORITHM + \"_\" + trackName[:-4] + \"_\" + CRASH_POS + \".png\"\n",
    "    \n",
    "    grid = track.getInputTextArray()\n",
    "    rows, cols = grid.shape\n",
    "\n",
    "    fig = plt.figure(figsize=(max(8, cols/10), max(8, rows/10)), dpi=200)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "    ax.set_xlim(0, cols)\n",
    "    ax.set_ylim(0, rows)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.invert_yaxis()\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Draw tiles\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            char = grid[r, c]\n",
    "            color = {'#': 'gray', 'F': 'limegreen', 'S': 'royalblue'}.get(char, 'white')\n",
    "            ax.add_patch(plt.Rectangle((c, r), 1, 1,\n",
    "                                       facecolor=color, edgecolor='black', linewidth=0.5))\n",
    "\n",
    "            # Small yellow square only on original '.' cells that are on the path\n",
    "            if (r, c) in path and grid[r, c] == '.':\n",
    "                ax.add_patch(plt.Rectangle((c + 0.25, r + 0.25), 0.5, 0.5,\n",
    "                                           facecolor='yellow', edgecolor='orange', linewidth=1))\n",
    "\n",
    "    # Gold line connecting path centers\n",
    "    if len(path) > 1:\n",
    "        x = [p[1] + 0.5 for p in path]\n",
    "        y = [p[0] + 0.5 for p in path]\n",
    "        ax.plot(x, y, color='gold', linewidth=6, solid_capstyle='round')\n",
    "\n",
    "    # Dark circles on Start and Finish\n",
    "    if path:\n",
    "        sr, sc = path[0]\n",
    "        fr, fc = path[-1]\n",
    "        ax.add_patch(plt.Circle((sc + 0.5, sr + 0.5), 0.4, color='darkblue'))\n",
    "        ax.add_patch(plt.Circle((fc + 0.5, fr + 0.5), 0.4, color='darkgreen'))\n",
    "\n",
    "    ax.set_title(f\"{ALGORITHM}  {track.getBestMoves()} moves\", fontsize=14, pad=20)\n",
    "    plt.savefig(pngFileName, dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    return\n",
    "\n",
    "def main(GROUP_ID, ALGORITHM, TRACK_NAME, CRASH_POS): \n",
    "\n",
    "    inputTextArray = fileImport(TRACK_NAME)\n",
    "    track = createTrack(inputTextArray, CRASH_POS)\n",
    "    \n",
    "    if (ALGORITHM == 'ValItr'):\n",
    "        # code to run variable elimination\n",
    "        # will be method on Network class\n",
    "        print(\"run Value Iteration\")\n",
    "        track.doValueIteration()\n",
    "        \n",
    "    elif (ALGORITHM == 'QLrng'):\n",
    "        # code to run gibbs sampling\n",
    "        # will be method on Network class\n",
    "        print(\"run Q-Learning\")\n",
    "        track.doQLearning()\n",
    "\n",
    "    elif (ALGORITHM == 'SARSA'):\n",
    "        # code to run gibbs sampling\n",
    "        # will be method on Network class\n",
    "        print(\"run State-Action-Reward-State-Action\")\n",
    "        track.doSARSA()\n",
    "        \n",
    "    else:\n",
    "        print(\"Not a valid algorithm. Terminating...\")\n",
    "        sys.exit() # exit program\n",
    "\n",
    "    print(\"Moves of Best Run: \" + str(track.getBestMoves()))\n",
    "\n",
    "    saveOutput(GROUP_ID, ALGORITHM, TRACK_NAME, CRASH_POS, track)\n",
    "    \n",
    "\n",
    "main(GROUP_ID, ALGORITHM, TRACK_NAME, CRASH_POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ea0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e6d6f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6809e034-1245-4fc1-8cba-fc502efc2668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
